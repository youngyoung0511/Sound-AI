{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aLv-hVihc9jD",
        "WRTDrL3IuEyA",
        "BvxPyeygyDZS",
        "_RE61huX070o"
      ],
      "authorship_tag": "ABX9TyOrc82xtQuz2N2nitHKPz3v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngyoung0511/Sound-AI/blob/main/%EC%84%9C%EC%98%81_0520.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습 시도--- 성공"
      ],
      "metadata": {
        "id": "aLv-hVihc9jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # pad_sequences 추가\n",
        "\n",
        "\n",
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17AmXUhdeeJo",
        "outputId": "f69452d6-4627-4288-826b-72f611f7c6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                             feature  label\n",
            "0  [[-0.6867080926895142, -0.35630643367767334, -...      9\n",
            "1  [[-0.5121172070503235, -0.15281927585601807, -...     10\n",
            "2  [[-0.5510217547416687, -0.40891343355178833, 0...     11\n",
            "3  [[-1.0, -0.7065231204032898, -0.52293550968170...     12\n",
            "4  [[-0.6754663586616516, -0.8131034970283508, -0...     13\n",
            "5  [[-0.46315479278564453, -0.48231905698776245, ...    209\n",
            "6  [[-0.45506036281585693, -0.4036714434623718, -...    309\n",
            "7  [[-0.4599418640136719, -0.3838350176811218, -0...    409\n",
            "8  [[-0.5104864239692688, -0.33293116092681885, -...    509\n",
            "9  [[-0.39017772674560547, -0.3200284242630005, -...    609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "# 이미 features와 labels가 데이터 프레임에 포함되어 있으므로, 이를 numpy array로 변환합니다.\n",
        "# 문자열로 인코딩된 리스트를 실제 리스트로 변환하고 패딩을 적용합니다.\n",
        "features = df['feature'].apply(eval).tolist()\n",
        "\n",
        "# 최대 길이 및 최대 차원 찾기\n",
        "max_len = max(len(feature) for feature in features)\n",
        "max_dim = max(len(feature[0]) if len(feature) > 0 else 0 for feature in features)\n",
        "print(f\"Max length of features: {max_len}\")\n",
        "print(f\"Max dimension of features: {max_dim}\")\n",
        "\n",
        "# 모든 시퀀스를 동일한 길이와 차원으로 패딩\n",
        "padded_features = np.array([np.pad(feature, ((0, max_len - len(feature)), (0, max_dim - len(feature[0]))), mode='constant') if len(feature) > 0 else np.zeros((max_len, max_dim)) for feature in features], dtype='float32')\n",
        "\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n",
        "\n",
        "# X 배열의 형상 출력\n",
        "print(f\"Shape of X: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jYJgr1RgGi3",
        "outputId": "9cdfbfd8-6755-41e4-969d-623dca5dc590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of features: 1025\n",
            "Max dimension of features: 130\n",
            "Shape of X: (147, 1025, 130)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN을 위해 차원 추가\n",
        "if len(X.shape) == 3:  # 확인된 형상이 (samples, timesteps, features)인 경우\n",
        "    X = X[..., np.newaxis]  # 차원 추가 (samples, timesteps, features, 1)\n",
        "\n",
        "print(f\"New shape of X: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAaU5T-eg9SX",
        "outputId": "a3e1eaf7-b2f3-4095-8ce1-5044e1592cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of X: (147, 1025, 130, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨의 최대값 확인\n",
        "num_classes = np.max(y) + 1\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SSdVoBVerhh",
        "outputId": "0b2a4b17-4da6-4219-e6a9-84439d819750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의 함수\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))  # num_classes 적용\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "p0uQzWqoetGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "input_shape = (X.shape[1], X.shape[2], 1)\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "t9Y6-ZyPeulh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 콜백 설정\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# 모델 평가\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSSRplYepLBR",
        "outputId": "b0d4e2a8-9fa1-4a50-fb13-90f5d9aa255f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 15s 5s/step - loss: 5.9333 - accuracy: 0.0171 - val_loss: 7.4847 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 4.8958 - accuracy: 0.0855 - val_loss: 8.3586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 4.1334 - accuracy: 0.1453 - val_loss: 8.7924 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 3.7112 - accuracy: 0.1368 - val_loss: 8.7337 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 3.3095 - accuracy: 0.2051 - val_loss: 10.1416 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 2.9805 - accuracy: 0.2308 - val_loss: 10.9999 - val_accuracy: 0.0667\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 2.8711 - accuracy: 0.2650 - val_loss: 10.3096 - val_accuracy: 0.0667\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 2.4951 - accuracy: 0.3248 - val_loss: 11.1027 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 135ms/step - loss: 2.4339 - accuracy: 0.3333 - val_loss: 12.2949 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 2.0399 - accuracy: 0.4359 - val_loss: 12.6879 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 344ms/step - loss: 1.8999 - accuracy: 0.4615 - val_loss: 12.7635 - val_accuracy: 0.0667\n",
            "1/1 - 0s - loss: 7.4847 - accuracy: 0.0000e+00 - 51ms/epoch - 51ms/step\n",
            "Validation Loss: 7.484734058380127\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# accuracy 증가시도---안 늘어남..."
      ],
      "metadata": {
        "id": "WRTDrL3IuEyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "W6HTq0fYuJ2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_CdojusuLyA",
        "outputId": "d978d1e4-fd16-4833-e6e1-c35dc008d38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                             feature  label\n",
            "0  [[-0.6867080926895142, -0.35630643367767334, -...      9\n",
            "1  [[-0.5121172070503235, -0.15281927585601807, -...     10\n",
            "2  [[-0.5510217547416687, -0.40891343355178833, 0...     11\n",
            "3  [[-1.0, -0.7065231204032898, -0.52293550968170...     12\n",
            "4  [[-0.6754663586616516, -0.8131034970283508, -0...     13\n",
            "5  [[-0.46315479278564453, -0.48231905698776245, ...    209\n",
            "6  [[-0.45506036281585693, -0.4036714434623718, -...    309\n",
            "7  [[-0.4599418640136719, -0.3838350176811218, -0...    409\n",
            "8  [[-0.5104864239692688, -0.33293116092681885, -...    509\n",
            "9  [[-0.39017772674560547, -0.3200284242630005, -...    609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "features = df['feature'].apply(eval).tolist()\n",
        "max_len = max(len(feature) for feature in features)\n",
        "max_dim = max(len(feature[0]) if len(feature) > 0 else 0 for feature in features)\n",
        "print(f\"Max length of features: {max_len}\")\n",
        "print(f\"Max dimension of features: {max_dim}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEbO5bluuOqA",
        "outputId": "cac8d1ca-c29d-4076-aa81-6b97052070e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of features: 1025\n",
            "Max dimension of features: 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_features = np.array([np.pad(feature, ((0, max_len - len(feature)), (0, max_dim - len(feature[0]))), mode='constant') if len(feature) > 0 else np.zeros((max_len, max_dim)) for feature in features], dtype='float32')\n",
        "\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLR7V3mGuQmU",
        "outputId": "113a52ac-cca9-42bd-daf2-a13064d1d54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (147, 1025, 130)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X.shape) == 3:\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "print(f\"New shape of X: {X.shape}\")\n",
        "num_classes = np.max(y) + 1\n",
        "print(f\"Number of classes: {num_classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJpOBP_ruVJ3",
        "outputId": "bdf1ec0e-b8ff-4a22-9516-bbc6ed4a8a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape of X: (147, 1025, 130, 1)\n",
            "Number of classes: 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))  # Dropout 추가\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "v6qX4xNuvnyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X.shape[1], X.shape[2], 1)\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)  # Learning rate scheduler 추가\n"
      ],
      "metadata": {
        "id": "5JbGTRz-vqCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,  # 에폭 수 증가\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF8i5sL6vu7t",
        "outputId": "7cfbf42d-5b83-40b0-b436-fd67d27007a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - ETA: 0s - loss: 9.9318 - accuracy: 0.0000e+00 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 14s 5s/step - loss: 9.9318 - accuracy: 0.0000e+00 - val_loss: 7.0727 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 18s 6s/step - loss: 7.0590 - accuracy: 0.0000e+00 - val_loss: 7.0124 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 28s 9s/step - loss: 6.8715 - accuracy: 0.0171 - val_loss: 6.9005 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 13s 4s/step - loss: 6.6849 - accuracy: 0.0256 - val_loss: 6.8049 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 21s 7s/step - loss: 6.3715 - accuracy: 0.0342 - val_loss: 6.7064 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 14s 4s/step - loss: 6.1622 - accuracy: 0.0427 - val_loss: 6.5766 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 20s 6s/step - loss: 5.7968 - accuracy: 0.0085 - val_loss: 6.5610 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 5.3247 - accuracy: 0.0513 - val_loss: 6.6507 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 38s 12s/step - loss: 4.8281 - accuracy: 0.1197 - val_loss: 6.4678 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 45s 15s/step - loss: 4.8307 - accuracy: 0.0940 - val_loss: 6.3370 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 4.5880 - accuracy: 0.0684 - val_loss: 6.5896 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 4.1969 - accuracy: 0.1026 - val_loss: 6.5399 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 4.1859 - accuracy: 0.1197 - val_loss: 6.4805 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 4.0722 - accuracy: 0.1368 - val_loss: 6.4455 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 1s 159ms/step - loss: 3.6740 - accuracy: 0.1453 - val_loss: 6.6219 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 3.5845 - accuracy: 0.1453 - val_loss: 6.7153 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 3.5446 - accuracy: 0.1538 - val_loss: 6.7003 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 3.2411 - accuracy: 0.2051 - val_loss: 7.1063 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 1s 136ms/step - loss: 3.3537 - accuracy: 0.2051 - val_loss: 6.9526 - val_accuracy: 0.0667 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 1s 339ms/step - loss: 3.2078 - accuracy: 0.2393 - val_loss: 6.7416 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "1/1 - 0s - loss: 6.3370 - accuracy: 0.0000e+00 - 37ms/epoch - 37ms/step\n",
            "Validation Loss: 6.336982250213623\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# accuracy 증가 시도 --- 학습률 조정, 드롭아웃 레이어 추가--- 안 늘어남"
      ],
      "metadata": {
        "id": "BvxPyeygyDZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습률 조정: Adam 옵티마이저의 학습률을 0.0001로 설정\n",
        "\n",
        "에포크 수 증가: 학습을 더 오래 진행\n",
        "\n",
        "드롭아웃 추가: 과적합을 방지하기 위해 드롭아웃 레이어를 추가"
      ],
      "metadata": {
        "id": "phl-1-j9yRKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 전처리\n",
        "features = df['feature'].apply(eval).tolist()\n",
        "max_len = max(len(feature) for feature in features)\n",
        "max_dim = max(len(feature[0]) if len(feature) > 0 else 0 for feature in features)\n",
        "\n",
        "padded_features = np.array([np.pad(feature, ((0, max_len - len(feature)), (0, max_dim - len(feature[0]))), mode='constant') if len(feature) > 0 else np.zeros((max_len, max_dim)) for feature in features], dtype='float32')\n",
        "\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n",
        "\n",
        "if len(X.shape) == 3:\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "num_classes = np.max(y) + 1\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))  # Dropout 추가\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "input_shape = (X.shape[1], X.shape[2], 1)\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=3,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "\n",
        ")\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "print(f'Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNHUEH43yGLE",
        "outputId": "ad05d63c-920c-45b6-ea40-be76b1814cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/3\n",
            "4/4 [==============================] - 2s 213ms/step - loss: 7.2270 - accuracy: 0.0000e+00 - val_loss: 7.2507 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 7.0962 - accuracy: 0.0000e+00 - val_loss: 7.2359 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 6.9517 - accuracy: 0.0000e+00 - val_loss: 7.1950 - val_accuracy: 0.0000e+00\n",
            "1/1 - 0s - loss: 7.1950 - accuracy: 0.0000e+00 - 35ms/epoch - 35ms/step\n",
            "Validation Loss: 7.195042133331299\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow로 CNN"
      ],
      "metadata": {
        "id": "_RE61huX070o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "배치 정규화 추가: 각 컨볼루션 레이어 뒤에 배치 정규화 레이어를 추가하여 학습을 안정화하고 과적합을 방지"
      ],
      "metadata": {
        "id": "0nn1Qtfe1IDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 전처리\n",
        "features = df['feature'].apply(eval).tolist()\n",
        "max_len = max(len(feature) for feature in features)\n",
        "max_dim = max(len(feature[0]) if len(feature) > 0 else 0 for feature in features)\n",
        "\n",
        "padded_features = np.array([np.pad(feature, ((0, max_len - len(feature)), (0, max_dim - len(feature[0]))), mode='constant') if len(feature) > 0 else np.zeros((max_len, max_dim)) for feature in features], dtype='float32')\n",
        "\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n",
        "\n",
        "if len(X.shape) == 3:\n",
        "    X = X[..., np.newaxis]\n",
        "\n",
        "num_classes = np.max(y) + 1\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPmIFEBo1I0i",
        "outputId": "91d133c1-f64d-4739-cee5-772928b9ead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 사용\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "input_shape = (X.shape[1], X.shape[2], 1)\n",
        "model = create_model(input_shape, num_classes)\n",
        "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
        "#history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val),callbacks=[checkpoint, early_stopping, reduce_lr])\n",
        "\n",
        "\n",
        "#val_loss, val_acc = model.evaluate(X_val,y_val)\n",
        "#test_loss, test_acc = model.evaluate(X_test,y_test)\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "print(f'Validation Accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcZq683l1K5S",
        "outputId": "e904ee3c-b727-47c5-cfc1-d0381b8326da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 15s 1s/step - loss: 50.3274 - accuracy: 0.0000e+00 - val_loss: 7.1332 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 1s 167ms/step - loss: 14.8666 - accuracy: 0.0000e+00 - val_loss: 7.6753 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 8.0231 - accuracy: 0.0171 - val_loss: 7.3437 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 7.3246 - accuracy: 0.0085 - val_loss: 7.3865 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 1s 160ms/step - loss: 7.0502 - accuracy: 0.0171 - val_loss: 7.4739 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 7.0278 - accuracy: 0.0085 - val_loss: 7.5303 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 7.1296 - accuracy: 0.0427 - val_loss: 7.4327 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 6.8157 - accuracy: 0.0342 - val_loss: 7.3335 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 1s 171ms/step - loss: 6.9858 - accuracy: 0.0085 - val_loss: 7.2835 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 1s 172ms/step - loss: 6.8727 - accuracy: 0.0256 - val_loss: 7.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 1s 163ms/step - loss: 6.9563 - accuracy: 0.0256 - val_loss: 8.0860 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 1s 175ms/step - loss: 6.8510 - accuracy: 0.0427 - val_loss: 9.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 6.7750 - accuracy: 0.0513 - val_loss: 10.9901 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 6.8463 - accuracy: 0.0427 - val_loss: 12.7893 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.7197 - accuracy: 0.0427 - val_loss: 13.2957 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 6.7123 - accuracy: 0.0513 - val_loss: 14.4515 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 6.8430 - accuracy: 0.0427 - val_loss: 16.3200 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 1s 166ms/step - loss: 6.8416 - accuracy: 0.0342 - val_loss: 18.7889 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 1s 169ms/step - loss: 6.6927 - accuracy: 0.0427 - val_loss: 20.7592 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 1s 158ms/step - loss: 6.7529 - accuracy: 0.0427 - val_loss: 21.9679 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 6.7780 - accuracy: 0.0342 - val_loss: 23.2996 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 1s 168ms/step - loss: 6.6947 - accuracy: 0.0598 - val_loss: 24.3673 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 1s 153ms/step - loss: 6.6424 - accuracy: 0.0427 - val_loss: 26.6917 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.6237 - accuracy: 0.0427 - val_loss: 28.4410 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 1s 152ms/step - loss: 6.7335 - accuracy: 0.0342 - val_loss: 29.9775 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.8044 - accuracy: 0.0342 - val_loss: 29.4462 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 6.7505 - accuracy: 0.0427 - val_loss: 28.4529 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.7118 - accuracy: 0.0427 - val_loss: 29.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 6.7098 - accuracy: 0.0427 - val_loss: 30.4444 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.7147 - accuracy: 0.0513 - val_loss: 31.6316 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.8990 - accuracy: 0.0342 - val_loss: 32.3912 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 6.6767 - accuracy: 0.0427 - val_loss: 31.5411 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.6496 - accuracy: 0.0513 - val_loss: 30.9947 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.8095 - accuracy: 0.0513 - val_loss: 31.6106 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 6.7950 - accuracy: 0.0256 - val_loss: 34.8516 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.5505 - accuracy: 0.0598 - val_loss: 39.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 1s 164ms/step - loss: 6.6811 - accuracy: 0.0427 - val_loss: 39.3431 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 6.7307 - accuracy: 0.0256 - val_loss: 38.5096 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 6.9570 - accuracy: 0.0256 - val_loss: 40.6111 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 1s 165ms/step - loss: 6.7364 - accuracy: 0.0427 - val_loss: 44.4150 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 6.6735 - accuracy: 0.0342 - val_loss: 51.5936 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 1s 170ms/step - loss: 6.7221 - accuracy: 0.0342 - val_loss: 56.7035 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 1s 173ms/step - loss: 6.6608 - accuracy: 0.0256 - val_loss: 60.9540 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 1s 157ms/step - loss: 6.8652 - accuracy: 0.0256 - val_loss: 57.8254 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 1s 151ms/step - loss: 6.6189 - accuracy: 0.0513 - val_loss: 49.3133 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 6.6385 - accuracy: 0.0342 - val_loss: 43.6967 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 1s 162ms/step - loss: 6.5494 - accuracy: 0.0513 - val_loss: 39.5165 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 6.5890 - accuracy: 0.0342 - val_loss: 36.9761 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 1s 149ms/step - loss: 6.6463 - accuracy: 0.0256 - val_loss: 35.2868 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 1s 148ms/step - loss: 6.5885 - accuracy: 0.0427 - val_loss: 35.5165 - val_accuracy: 0.0000e+00\n",
            "1/1 - 0s - loss: 35.5165 - accuracy: 0.0000e+00 - 42ms/epoch - 42ms/step\n",
            "Validation Loss: 35.51648712158203\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 증강을 더 잘해서 정확도를 올리는 방법을.................."
      ],
      "metadata": {
        "id": "RmWqWbxS36Gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch.optim as optim # 최적화 알고리즘들이 포함힘\n",
        "\n",
        "model = CNNclassification().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 1e-3 )\n",
        "scheduler = None\n",
        "\n",
        "model(torch.rand(10, 40, 12, 1).to(device))\n",
        "\n",
        "이 방법 시도해보자"
      ],
      "metadata": {
        "id": "XE_rpqn-b3qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch로 CNN"
      ],
      "metadata": {
        "id": "iKxvhYN1CKW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mport torch.optim as optim # 최적화 알고리즘들이 포함힘\n",
        "\n",
        "model = CNNclassification().to(device) criterion = torch.nn.CrossEntropyLoss().to(device) optimizer = torch.optim.SGD(params = model.parameters(), lr = 1e-3 ) scheduler = None\n",
        "\n",
        "model(torch.rand(10, 40, 12, 1).to(device))\n",
        "\n",
        "이 방법 시도해보자"
      ],
      "metadata": {
        "id": "Gbn6X4hUC4T_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 라이브러리 가져오기\n",
        "\n",
        "데이터 로드 및 전처리\n",
        "\n",
        "CNN 모델 정의\n",
        "\n",
        "손실 함수 및 옵티마이저 정의\n",
        "\n",
        "모델 학습 및 검증\n"
      ],
      "metadata": {
        "id": "Kab1PoMyD9L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터 전처리*"
      ],
      "metadata": {
        "id": "hUFPXMn4GP0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMuc7tBeEAai",
        "outputId": "161e14f4-05c2-40e2-9206-6e0759b41b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 추출 및 리스트 변환\n",
        "# csv 파일에서 feature 열을 추출\n",
        "#feature은 문자열 형태로 저장되어 있어서 리스트로 변환\n",
        "feature=df['feature'].apply(eval).tolist()"
      ],
      "metadata": {
        "id": "Cf8af4cGEvEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩을 통해 입력데이터의 크기를 동일하게 맞춤\n",
        "#패딩 값은 -1로\n",
        "\n",
        "max_len = max(len(feature) for feature in feature)\n",
        "max_dim = max(len(feature[0]) if len(feature) > 0 else 0 for feature in feature)\n",
        "\n",
        "# 패딩 값을 -1로 설정\n",
        "padded_features = np.array([np.pad(feature, ((0, max_len - len(feature)), (0, max_dim - len(feature[0]))), mode='constant', constant_values=-1) if len(feature) > 0 else -1 * np.ones((max_len, max_dim)) for feature in feature], dtype='float32')\n"
      ],
      "metadata": {
        "id": "3FWToRw3b_th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 데이터 및 레이블 변환\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n"
      ],
      "metadata": {
        "id": "DFX4kco4FwxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 데이터 차원 확장\n",
        "#3차원 -> 4차원\n",
        "\n",
        "if len(X.shape) == 3:\n",
        "    X = X[..., np.newaxis]\n"
      ],
      "metadata": {
        "id": "M1UVxXj_HaEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*레이블이 유효한 범위 내에 있는지 확인 및 범위 조정*"
      ],
      "metadata": {
        "id": "TwZDO3NvUVfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블이 유효한 범위 내에 있는지 확인 및 범위 조정\n",
        "min_label = y.min()\n",
        "y = y - min_label\n",
        "num_classes = y.max() + 1\n",
        "assert y.min() >= 0 and y.max() < num_classes, \"레이블이 유효한 범위를 벗어났습니다\"\n"
      ],
      "metadata": {
        "id": "A7-NbYKcUZo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PyTorch 텐서로 변환*"
      ],
      "metadata": {
        "id": "b77iwmLGZFO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 텐서로 변환\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "if len(X.shape) == 3:\n",
        "    X = X.unsqueeze(1)  # 채널 차원을 추가하여 [batch_size, 1, height, width]로 변환\n",
        "y = torch.tensor(y, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "I76IH9kfHkey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*num_classes 정의*"
      ],
      "metadata": {
        "id": "ECEE_mBVO-Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y를 numpy 배열로 변환\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "num_classes = len(torch.unique(y_tensor))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM9_aUK9PC45",
        "outputId": "ed450c01-e640-4007-9331-c924abeafc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-6611f4b038c7>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_tensor = torch.tensor(y, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# 디버깅을 위한 레이블 값 확인\n",
        "unique_labels = torch.unique(y)\n",
        "print(f'Unique labels in dataset: {unique_labels}')\n",
        "print(f'Num classes: {num_classes}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRo3cp6eQt2i",
        "outputId": "88704fe5-2c4b-4d1b-cf7f-d8e35e5f0202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in dataset: tensor([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
            "          12,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,  111,\n",
            "         112,  202,  203,  204,  205,  206,  207,  208,  209,  210,  211,  212,\n",
            "         303,  304,  305,  306,  307,  308,  309,  310,  311,  312,  404,  405,\n",
            "         406,  407,  408,  409,  410,  411,  412,  505,  506,  507,  508,  509,\n",
            "         510,  511,  512,  606,  607,  608,  609,  610,  611,  612,  707,  708,\n",
            "         709,  710,  711,  712,  808,  809,  810,  811,  812,  909,  910,  911,\n",
            "         912, 1010, 1011, 1012, 1111, 1112, 1212])\n",
            "Num classes: 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train, Test DataSet으로 분할*"
      ],
      "metadata": {
        "id": "BqJuCVlEHtz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X, y)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
      ],
      "metadata": {
        "id": "q92jLBJOHymP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터 증강*"
      ],
      "metadata": {
        "id": "m7kr6CN4IDqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강 기법 적용\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1))\n",
        "])\n",
        "\n",
        "class AugmentedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X, y = self.dataset[idx]\n",
        "        if self.transform:\n",
        "            X = self.transform(X)\n",
        "        return X, y\n",
        "\n",
        "augmented_train_dataset = AugmentedDataset(train_dataset, transform=transform)\n"
      ],
      "metadata": {
        "id": "xcwtFhojIGgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*DataLoader 생성*"
      ],
      "metadata": {
        "id": "QiZWlZZAH1HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(augmented_train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Ep6gPed_H5PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터 로더에서 배치 데이터 형식 확인*"
      ],
      "metadata": {
        "id": "H2LIy7EnRAR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더에서 배치 데이터 형식 확인\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f'X_batch shape: {X_batch.shape}, y_batch shape: {y_batch.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arWe5iyZRDrT",
        "outputId": "0caffef4-d8fc-4d1c-8c29-a6b3d162a965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_batch shape: torch.Size([32, 1025, 130, 1]), y_batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*CNN 모델 정의*"
      ],
      "metadata": {
        "id": "flG00mXcNEl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "class CNNclassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNclassification, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * (max_len // 8) * (max_dim // 8), 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.bn1(torch.relu(self.conv1(x))))\n",
        "        x = self.pool2(self.bn2(torch.relu(self.conv2(x))))\n",
        "        x = self.pool3(self.bn3(torch.relu(self.conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNNclassification().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "glM53K5JNGyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*모델 학습 함수 정의*"
      ],
      "metadata": {
        "id": "UkjeL2joODqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 함수 정의\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=50):\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # 디버깅 문구\n",
        "            print(f'X_batch shape: {X_batch.shape}, y_batch shape: {y_batch.shape}')\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n"
      ],
      "metadata": {
        "id": "uZ-7UKozPKfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*모델 학습 및 검증*"
      ],
      "metadata": {
        "id": "dOTJtXjsPOip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 검증\n",
        "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "QTv7r_DaPQph",
        "outputId": "85b83901-bc9f-424e-de7f-ad8b75d6a181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_batch shape: torch.Size([32, 1025, 130, 1]), y_batch shape: torch.Size([32])\n",
            "Input shape: torch.Size([32, 1025, 130, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[32, 1025, 130, 1] to have 1 channels, but got 1025 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-96b95c5cd9f9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습 및 검증\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-0f0c792fd51e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-a3bfdf962ce4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Input shape: {x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'After conv1: {x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[32, 1025, 130, 1] to have 1 channels, but got 1025 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7AbHdVNOdDLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***입력 텐서가 컨볼루션 레이어에 전달될 때 형상이 올바르지 않아서 발생한 오류***\n",
        "\n",
        "입력 데이터의 형상 확인: 입력 텐서의 형상이 [batch_size, 1, height, width]인지 확인합니다.\n",
        "\n",
        "데이터 변환 확인: 데이터셋에 적용되는 변환이 입력 데이터의 차원을 올바르게 처리하는지 확인합니다."
      ],
      "metadata": {
        "id": "jUw21pLsdROJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Google Drive 마운트 및 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 추출 및 리스트 변환\n",
        "feature = df['feature'].apply(eval).tolist()\n",
        "\n",
        "# 패딩을 통해 입력데이터의 크기를 동일하게 맞춤\n",
        "max_len = max(len(f) for f in feature)\n",
        "max_dim = max(len(f[0]) if len(f) > 0 else 0 for f in feature)\n",
        "\n",
        "padded_features = np.array([np.pad(f, ((0, max_len - len(f)), (0, max_dim - len(f[0]))), mode='constant', constant_values=-1) if len(f) > 0 else -1 * np.ones((max_len, max_dim)) for f in feature], dtype='float32')\n",
        "\n",
        "# 입력 데이터 및 레이블 변환\n",
        "X = np.array(padded_features)\n",
        "y = np.array(df['label'].tolist())\n",
        "\n",
        "# 입력 데이터 차원 확장\n",
        "if len(X.shape) == 3:\n",
        "    X = X[:, np.newaxis, :, :]  # 채널 차원을 추가하여 [batch_size, 1, height, width]로 변환\n",
        "\n",
        "# 레이블이 유효한 범위 내에 있는지 확인 및 범위 조정\n",
        "min_label = y.min()\n",
        "y = y - min_label\n",
        "num_classes = y.max() + 1\n",
        "assert y.min() >= 0 and y.max() < num_classes, \"레이블이 유효한 범위를 벗어났습니다\"\n",
        "\n",
        "# PyTorch 텐서로 변환\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# 데이터 증강 기법 적용\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1))\n",
        "])\n",
        "\n",
        "class AugmentedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X, y = self.dataset[idx]\n",
        "        if self.transform:\n",
        "            X = self.transform(X)\n",
        "        return X, y\n",
        "\n",
        "augmented_train_dataset = AugmentedDataset(train_dataset, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(augmented_train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 데이터 로더에서 배치 데이터 형식 확인\n",
        "X_batch, y_batch = next(iter(train_loader))\n",
        "print(f'X_batch shape: {X_batch.shape}, y_batch shape: {y_batch.shape}')\n",
        "\n",
        "# CNN 모델 정의\n",
        "class CNNclassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNclassification, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * (max_len // 8) * (max_dim // 8), 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.bn1(torch.relu(self.conv1(x))))\n",
        "        x = self.pool2(self.bn2(torch.relu(self.conv2(x))))\n",
        "        x = self.pool3(self.bn3(torch.relu(self.conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNNclassification().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# 모델 학습 함수 정의\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=50):\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "# 모델 학습 및 검증\n",
        "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR5JBTPEeGgp",
        "outputId": "cdd1179e-13ab-4b7e-e472-aa51ee673e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "X_batch shape: torch.Size([32, 1, 1025, 130]), y_batch shape: torch.Size([32])\n",
            "Epoch 1/3, Train Loss: 7.3396, Val Loss: 7.0860\n",
            "Epoch 2/3, Train Loss: 7.1467, Val Loss: 7.0890\n",
            "Epoch 3/3, Train Loss: 6.9122, Val Loss: 7.0786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*유닛테스트*"
      ],
      "metadata": {
        "id": "t9VkcVqJsaRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_cnn_model():\n",
        "    # 가상의 데이터를 생성하여 모델 테스트\n",
        "    test_input = torch.randn(1, 1, max_len, max_dim).to(device)  # 임의의 입력 데이터\n",
        "    test_output = model(test_input)\n",
        "\n",
        "    assert test_output.shape == (1, num_classes), f\"Output shape mismatch: {test_output.shape} != (1, {num_classes})\"\n",
        "    print(\"Unit test passed!\")\n",
        "\n",
        "test_cnn_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quL3Ayn9scJM",
        "outputId": "41d95c15-30a9-4e8e-ad5c-d79603f122af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*검증함수코드*"
      ],
      "metadata": {
        "id": "0iRP9Mo4sVhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            test_loss += loss.item() * X_batch.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += predicted.eq(y_batch).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# 모델 평가\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACBu9mqasRch",
        "outputId": "e69f1e86-7fe5-4000-cd72-5e6eab46b9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 7.1872, Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*하이퍼파라미터* *튜닝*  이거 에폭 개늘려서 시각화한거 봐보자"
      ],
      "metadata": {
        "id": "_oby0R8kskg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search 또는 Random Search를 사용하여 다양한 하이퍼파라미터 조합을 시도"
      ],
      "metadata": {
        "id": "ljTYQCMYsqEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(train_losses, val_losses):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PNGUgeL2sqkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 함수 수정\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=30):\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    plot_training_history(train_losses, val_losses)\n",
        "\n",
        "# 모델 학습 및 검증\n",
        "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hI4urld1swit",
        "outputId": "2c68dc71-ce7d-48ce-d404-30493973c859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Train Loss: 7.0005, Val Loss: 7.0819\n",
            "Epoch 2/30, Train Loss: 6.8191, Val Loss: 7.0709\n",
            "Epoch 3/30, Train Loss: 6.9469, Val Loss: 7.0670\n",
            "Epoch 4/30, Train Loss: 6.8534, Val Loss: 7.0903\n",
            "Epoch 5/30, Train Loss: 6.8688, Val Loss: 7.1095\n",
            "Epoch 6/30, Train Loss: 6.8612, Val Loss: 7.0726\n",
            "Epoch 7/30, Train Loss: 6.9160, Val Loss: 7.0407\n",
            "Epoch 8/30, Train Loss: 6.8468, Val Loss: 7.0237\n",
            "Epoch 9/30, Train Loss: 6.7992, Val Loss: 7.0093\n",
            "Epoch 10/30, Train Loss: 6.8410, Val Loss: 6.9961\n",
            "Epoch 11/30, Train Loss: 6.8027, Val Loss: 6.9861\n",
            "Epoch 12/30, Train Loss: 6.7105, Val Loss: 6.9865\n",
            "Epoch 13/30, Train Loss: 6.7030, Val Loss: 6.9765\n",
            "Epoch 14/30, Train Loss: 6.8015, Val Loss: 6.9816\n",
            "Epoch 15/30, Train Loss: 6.6519, Val Loss: 6.9727\n",
            "Epoch 16/30, Train Loss: 6.8609, Val Loss: 6.9738\n",
            "Epoch 17/30, Train Loss: 6.7450, Val Loss: 6.9595\n",
            "Epoch 18/30, Train Loss: 6.7953, Val Loss: 6.9556\n",
            "Epoch 19/30, Train Loss: 6.6620, Val Loss: 6.9539\n",
            "Epoch 20/30, Train Loss: 6.7423, Val Loss: 6.9544\n",
            "Epoch 21/30, Train Loss: 6.7417, Val Loss: 6.9556\n",
            "Epoch 22/30, Train Loss: 6.7089, Val Loss: 6.9538\n",
            "Epoch 23/30, Train Loss: 6.8209, Val Loss: 6.9546\n",
            "Epoch 24/30, Train Loss: 6.5740, Val Loss: 6.9535\n",
            "Epoch 25/30, Train Loss: 6.6377, Val Loss: 6.9531\n",
            "Epoch 26/30, Train Loss: 6.7385, Val Loss: 6.9536\n",
            "Epoch 27/30, Train Loss: 6.6148, Val Loss: 6.9522\n",
            "Epoch 28/30, Train Loss: 6.7158, Val Loss: 6.9519\n",
            "Epoch 29/30, Train Loss: 6.6550, Val Loss: 6.9522\n",
            "Epoch 30/30, Train Loss: 6.6690, Val Loss: 6.9525\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터 증강, 하이퍼파라미터 튜닝, 모델 아키텍처 개선*"
      ],
      "metadata": {
        "id": "CfYE_dRr5x6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*데이터 증강*"
      ],
      "metadata": {
        "id": "eMcYR5wY6hom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomResizedCrop((max_len, max_dim), scale=(0.8, 1.0))\n",
        "])\n"
      ],
      "metadata": {
        "id": "jmmxXzZo6la8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*하이퍼파라미터* *튜닝*"
      ],
      "metadata": {
        "id": "s7mC6Esw6nE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # SGD 대신 Adam 사용\n"
      ],
      "metadata": {
        "id": "A3cwQoTb6p1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*모델아키텍처* *개선*"
      ],
      "metadata": {
        "id": "bToeat8z6ts9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNclassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNclassification, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(256 * (max_len // 16) * (max_dim // 16), 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.bn1(torch.relu(self.conv1(x))))\n",
        "        x = self.pool2(self.bn2(torch.relu(self.conv2(x))))\n",
        "        x = self.pool3(self.bn3(torch.relu(self.conv3(x))))\n",
        "        x = self.pool4(self.bn4(torch.relu(self.conv4(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BYcgkune6voJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*조기종료 및 학습률 감소*"
      ],
      "metadata": {
        "id": "-1K-jY7f6zZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss 시각화\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy 시각화\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
        "    plt.plot(epochs, val_accuracies, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=50):\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "            _, predicted = output.max(1)\n",
        "            total_train += y_batch.size(0)\n",
        "            correct_train += predicted.eq(y_batch).sum().item()\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracy = 100. * correct_train / total_train\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "                _, predicted = output.max(1)\n",
        "                total_val += y_batch.size(0)\n",
        "                correct_val += predicted.eq(y_batch).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracy = 100. * correct_val / total_val\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)\n",
        "\n",
        "# 모델 학습 및 검증\n",
        "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "V4uMaEDl617f",
        "outputId": "98fdf213-a430-4302-c90e-bc042feb0b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-09a4286ffb74>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# 모델 학습 및 검증\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-09a4286ffb74>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2722d19f9d05>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}