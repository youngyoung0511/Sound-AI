{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0fxUNrMH_Fr2",
        "pM3wFB2XKDoi"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjxfl54IcqNrJVHjFi4CFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngyoung0511/Sound-AI/blob/main/0515.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코랩에 연동"
      ],
      "metadata": {
        "id": "0fxUNrMH_Fr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "6Gk5LrdyDZvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWn-rYtRDY5g",
        "outputId": "1dbd4835-fce2-43b7-f92b-3fbcf95425eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "csv 파일 로드하기"
      ],
      "metadata": {
        "id": "IsmnSxMKDfFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "_n36MNxjDhtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "로드한 데이터 프레임 확인하기"
      ],
      "metadata": {
        "id": "G3zBNpXLE_CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(10))  # 데이터 프레임의 처음 몇 줄 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1BxAPfhFBeJ",
        "outputId": "7ae73064-13ba-4d84-ac2f-a136a6f3014e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             feature  label\n",
            "0  [[-0.6867080926895142, -0.35630643367767334, -...      9\n",
            "1  [[-0.5121172070503235, -0.15281927585601807, -...     10\n",
            "2  [[-0.5510217547416687, -0.40891343355178833, 0...     11\n",
            "3  [[-1.0, -0.7065231204032898, -0.52293550968170...     12\n",
            "4  [[-0.6754663586616516, -0.8131034970283508, -0...     13\n",
            "5  [[-0.46315479278564453, -0.48231905698776245, ...    209\n",
            "6  [[-0.45506036281585693, -0.4036714434623718, -...    309\n",
            "7  [[-0.4599418640136719, -0.3838350176811218, -0...    409\n",
            "8  [[-0.5104864239692688, -0.33293116092681885, -...    509\n",
            "9  [[-0.39017772674560547, -0.3200284242630005, -...    609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 중복된 파일 삭제"
      ],
      "metadata": {
        "id": "pM3wFB2XKDoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Td8G95_eKHQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "중복된 파일 확인 및 제거"
      ],
      "metadata": {
        "id": "N7qYp4mIKUGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일 불러오기\n",
        "file_path = \"/content/drive/My Drive/soundAI/df_concat.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 레이블 정의 및 정렬\n",
        "df = df.sort_values(by='label')\n",
        "\n",
        "# 중복된 파일 확인\n",
        "duplicate_files = df[df.duplicated(subset=['label'])]"
      ],
      "metadata": {
        "id": "60__OuzTKWB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#중복된 파일이 있으면 출력\n",
        "\n",
        "if not duplicate_files.empty:\n",
        "  print(\"중복된 파일 있음: \")\n",
        "  print(duplicate_files)\n",
        "else:\n",
        "  print(\"중복된 파일 없음\")\n",
        "\n",
        "#레이블 정의 및 정렬\n",
        "df=df.sort_values(by='label')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MNx8teDL6Mk",
        "outputId": "374a2734-b2ff-403c-cb63-23f96f00bb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "중복된 파일 있음: \n",
            "                                               feature  label\n",
            "55   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    105\n",
            "109  [[-0.8014881014823914, -0.5750018358230591, -0...    106\n",
            "80   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    107\n",
            "111  [[-0.521267294883728, -0.3966425061225891, -1....    108\n",
            "52   [[-0.40613096952438354, -0.5485154986381531, -...    109\n",
            "53   [[-0.5126131176948547, -0.1527547836303711, -0...    110\n",
            "114  [[-0.5547134280204773, -0.4877322316169739, 0....    111\n",
            "115  [[-1.0, -1.0, -0.6883800625801086, -1.0, -0.59...    112\n",
            "44   [[-1.0, -0.8594150543212891, -0.74589765071868...    113\n",
            "100  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    205\n",
            "69   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    206\n",
            "82   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    207\n",
            "92   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    208\n",
            "5    [[-0.46315479278564453, -0.48231905698776245, ...    209\n",
            "15   [[-0.515091061592102, -0.22984886169433594, -0...    210\n",
            "125  [[-0.5937517881393433, -0.026881039142608643, ...    211\n",
            "36   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    212\n",
            "45   [[-0.5727807283401489, -0.061064064502716064, ...    213\n",
            "129  [[-0.8183351755142212, -0.3985697031021118, -0...    305\n",
            "70   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    306\n",
            "131  [[-0.5036012530326843, -0.6266977190971375, -0...    307\n",
            "93   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    308\n",
            "133  [[-0.4547073245048523, -0.39332592487335205, -...    309\n",
            "134  [[-0.5131413340568542, -0.1537858247756958, -0...    310\n",
            "27   [[-0.5950658917427063, -0.02881443500518799, -...    311\n",
            "136  [[-1.0, -0.776755690574646, -0.863499283790588...    312\n",
            "46   [[-0.9140735864639282, -0.9487924575805664, -1...    313\n",
            "138  [[-0.8332515954971313, -0.38745343685150146, -...    405\n",
            "72   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    406\n",
            "84   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    407\n",
            "98   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    408\n",
            "7    [[-0.4599418640136719, -0.3838350176811218, -0...    409\n",
            "143  [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    410\n",
            "144  [[-0.5902608633041382, -0.023035407066345215, ...    411\n",
            "145  [[-0.6599298715591431, -0.3365131616592407, -0...    412\n",
            "47   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    413\n",
            "62   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    509\n",
            "63   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    510\n",
            "64   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    511\n",
            "66   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    512\n",
            "65   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    513\n",
            "74   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    609\n",
            "19   [[-0.47465646266937256, -0.13256341218948364, ...    610\n",
            "30   [[-0.6209961175918579, -0.0047512054443359375,...    611\n",
            "39   [[-0.7950889468193054, -0.589225172996521, -0....    612\n",
            "49   [[-0.8005477786064148, -0.5828671455383301, -0...    613\n",
            "85   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    709\n",
            "21   [[-0.420013427734375, -0.15467357635498047, -0...    710\n",
            "88   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    711\n",
            "40   [[-0.50127112865448, -0.598981499671936, -0.57...    712\n",
            "89   [[-0.5050737261772156, -0.5855682492256165, -0...    713\n",
            "11   [[-0.481329083442688, -0.2718355059623718, -0....    809\n",
            "22   [[-0.43927985429763794, -0.7231189608573914, -...    810\n",
            "32   [[-0.7349036931991577, -0.00803530216217041, -...    811\n",
            "94   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    812\n",
            "95   [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...    813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일에서 데이터 읽기 (예시 파일 경로: 'input_file.csv')\n",
        "input_file = '/content/drive/My Drive/soundAI/df_concat.csv'\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "\n",
        "#중복된 행 삭제\n",
        "df=df.drop_duplicates(subset=['feature'])\n",
        "\n",
        "#삭제된 데이터 확인\n",
        "print(\"중복된 데이터 삭제됨\")\n",
        "print(df.head(20))\n",
        "\n",
        "# DataFrame을 새로운 CSV 파일로 저장\n",
        "output_file = 'clean_df.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"DataFrame이 '{output_file}' 파일로 저장되었습니다.\")\n",
        "\n",
        "#컴퓨터로 다운로드\n",
        "from google.colab import files\n",
        "\n",
        "files.download('clean_df.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_en7FAXMpi7",
        "outputId": "1d222b0a-c9d9-4b39-feb5-5a050db887fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "중복된 데이터 삭제됨\n",
            "                                              feature  label\n",
            "0   [[-0.6867080926895142, -0.35630643367767334, -...      9\n",
            "1   [[-0.5121172070503235, -0.15281927585601807, -...     10\n",
            "2   [[-0.5510217547416687, -0.40891343355178833, 0...     11\n",
            "3   [[-1.0, -0.7065231204032898, -0.52293550968170...     12\n",
            "4   [[-0.6754663586616516, -0.8131034970283508, -0...     13\n",
            "5   [[-0.46315479278564453, -0.48231905698776245, ...    209\n",
            "6   [[-0.45506036281585693, -0.4036714434623718, -...    309\n",
            "7   [[-0.4599418640136719, -0.3838350176811218, -0...    409\n",
            "8   [[-0.5104864239692688, -0.33293116092681885, -...    509\n",
            "9   [[-0.39017772674560547, -0.3200284242630005, -...    609\n",
            "10  [[-0.42676103115081787, -0.5264301300048828, -...    709\n",
            "11  [[-0.481329083442688, -0.2718355059623718, -0....    809\n",
            "12  [[-0.7413137555122375, -0.0137939453125, -0.24...    911\n",
            "13  [[-0.45483624935150146, -0.4007296562194824, -...    912\n",
            "14  [[-0.4545859098434448, -0.4064016342163086, -0...    913\n",
            "15  [[-0.515091061592102, -0.22984886169433594, -0...    210\n",
            "16  [[-0.5120776891708374, -0.1529693603515625, -0...    310\n",
            "17  [[-0.5188209414482117, -0.15497827529907227, -...    410\n",
            "18  [[-0.4872104525566101, -0.1181599497795105, -0...    510\n",
            "19  [[-0.47465646266937256, -0.13256341218948364, ...    610\n",
            "DataFrame이 'clean_df.csv' 파일로 저장되었습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72259316-ac31-4052-a746-b6c6232726a4\", \"clean_df.csv\", 188616597)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**중복된 데이터 삭제한거-->df**"
      ],
      "metadata": {
        "id": "f36Ei4UxPRko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패딩"
      ],
      "metadata": {
        "id": "bM0YFU96PuTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "중복된 데이터 삭제한 거: df에 저장\n",
        "\n",
        "df에 있는 데이터 -1로 패딩하면서 길이 맞추기"
      ],
      "metadata": {
        "id": "Rkf7SpKk63RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터는 feature과 label로 구성되어있고\n",
        "#feature가 리스트 형태로 되어 있으면 각 feature 리스트의 길이를 맞추기 위해 패딩 적용해야함\n",
        "#가장 긴 feature 리스트를 기준으로 다른 feature 리스트에 -1로 패딩\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#csv 파일 경로\n",
        "file_path='/content/drive/My Drive/soundAI/clean_df.csv'\n",
        "\n",
        "#csv 파일 불러오기\n",
        "df=pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "uEQK57l165hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우선 각 행의 길이를 동일하게 맞추기 위해 데이터가 어떻게 생겼는지 알아야함."
      ],
      "metadata": {
        "id": "xJ16_k7CKLBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data_col='feature'\n",
        "\n",
        "import ast\n",
        "\n",
        "# 문자열을 리스트로 변환\n",
        "df[data_col] = df[data_col].apply(ast.literal_eval)\n",
        "\n",
        "#최대 길이 찾기\n",
        "max_length=df[data_col].apply(len).max()\n",
        "\n",
        "#-1로 패딩하는 함수 정의\n",
        "def pad_list(lst,max_length,padding_value=-1):\n",
        "  return lst+[padding_value]*(max_length-len(lst))\n",
        "\n",
        "#각 행을 -1로 패딩\n",
        "df[data_col]=df[data_col].apply(lambda x: pad_list(x,max_length))\n",
        "\n",
        "#결과 확인\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "pNLLXiBSKRLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 CSV 파일 경로\n",
        "output_file_path = '/content/drive/My Drive/soundAI/padded_clean_df.csv'\n",
        "\n",
        "# CSV 파일로 저장\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Colab 로컬 파일 시스템에도 저장\n",
        "local_output_path = 'padded_clean_df.csv'\n",
        "df.to_csv(local_output_path, index=False)\n",
        "\n",
        "# 컴퓨터로 다운로드\n",
        "from google.colab import files\n",
        "files.download(local_output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTM1L4Q5MxKP",
        "outputId": "6933dc92-f7bc-44fd-9e19-ad115703f78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c4bf4d1-012e-4823-a23c-b074e65a85fe\", \"padded_clean_df.csv\", 188616597)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 증강"
      ],
      "metadata": {
        "id": "9vDSRtQXO2ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# CSV 파일 경로\n",
        "file_path = '/content/drive/My Drive/soundAI/padded_clean_df.csv'\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJNjer_nZm6D",
        "outputId": "74616731-9c52-4034-fc8f-b941070feac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강 함수 정의\n",
        "def augment_data(data):\n",
        "    # 데이터 증강하는 코드 작성\n",
        "    augmented_data = data  # 예시로 데이터를 그대로 복사하는 것으로 가정합니다.\n",
        "    return augmented_data\n",
        "\n",
        "# 데이터 증강 및 새로운 데이터프레임에 추가\n",
        "augmented_df = pd.DataFrame(columns=df.columns)\n",
        "for index, row in df.iterrows():\n",
        "    augmented_data = augment_data(row)  # 데이터 증강 함수 호출\n",
        "    augmented_df = pd.concat([augmented_df, pd.DataFrame(augmented_data).transpose()], ignore_index=True)\n",
        "\n",
        "# 증강된 데이터 저장\n",
        "augmented_df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "PlVnRjZGZxcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 증강 함수 정의\n",
        "\n",
        "def add_noise(data, noise_factor=0.05):\n",
        "    noise = np.random.normal(0, noise_factor, data.shape)\n",
        "    return data + noise\n",
        "\n",
        "def time_shift(data, shift_max=2):\n",
        "    shift = np.random.randint(-shift_max, shift_max)\n",
        "    return np.roll(data, shift, axis=0)\n",
        "\n",
        "def frequency_shift(data, shift_max=2):\n",
        "    shift = np.random.randint(-shift_max, shift_max)\n",
        "    return np.roll(data, shift, axis=1)\n",
        "\n",
        "def augment_data(data, num_augments=5, noise_factor=0.05, shift_max=2):\n",
        "    augmented_data = []\n",
        "    for _ in range(num_augments):\n",
        "        new_data = data.copy()\n",
        "\n",
        "        # 랜덤하게 증강 기법 선택 및 적용\n",
        "        if np.random.rand() < 0.5:\n",
        "            new_data = add_noise(new_data, noise_factor)\n",
        "        if np.random.rand() < 0.5:\n",
        "            new_data = time_shift(new_data, shift_max)\n",
        "        if np.random.rand() < 0.5:\n",
        "            new_data = frequency_shift(new_data, shift_max)\n",
        "\n",
        "        augmented_data.append(new_data.tolist())\n",
        "    return augmented_data"
      ],
      "metadata": {
        "id": "az8IJpFtaCZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 증강 적용\n",
        "#원래 데이터를 포함하여 증간된 데이터셋 생성\n",
        "\n",
        "augmented_rows=[]\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    original_data = np.array(row[data_col])\n",
        "    augmented_data = augment_data(original_data)\n",
        "    for aug_data in augmented_data:\n",
        "        augmented_row = row.copy()\n",
        "        augmented_row[data_col] = aug_data\n",
        "        augmented_rows.append(augmented_row)\n",
        "\n",
        "# 원래 데이터도 포함\n",
        "df_augmented = pd.concat([df] + [pd.DataFrame(augmented_rows)], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "7eiGqL0Oa-eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 증강된 데이터 확인 및 저장\n",
        "\n",
        "print(df_augmented.head())\n",
        "\n",
        "# 새로운 증강된 CSV 파일 경로\n",
        "output_file_path = '/content/drive/My Drive/soundAI/augmented_clean_df.csv'\n",
        "\n",
        "# 증강된 CSV 파일로 저장\n",
        "#df_augmented.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Colab 로컬 파일 시스템에도 저장\n",
        "#local_output_path = 'augmented_clean_df.csv'\n",
        "#df_augmented.to_csv(local_output_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "adxY8HILbYB7",
        "outputId": "140c4842-e6ae-41da-8e1b-ac49e0adc885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_augmented' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-f5732f262b47>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 증강된 데이터 확인 및 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 새로운 증강된 CSV 파일 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_augmented' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbS8OT4cYtnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 매핑"
      ],
      "metadata": {
        "id": "RRbsbVhldjDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "증강된 데이터를 특정범위로 매핑하려면 각 데이터 포인트를 해당 범위 내의 값으로 정규화 또는 스케일링 해야함.\n",
        "이를 위해 min max 스케일링 사용"
      ],
      "metadata": {
        "id": "F-W7NMeido8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 증강된 CSV 파일 경로\n",
        "file_path = '/content/drive/My Drive/soundAI/augmented_clean_df.csv'\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 개수 확인\n",
        "num_rows = len(df)\n",
        "print(f\"총 데이터 개수: {num_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBhLB31Ndzd-",
        "outputId": "466a82a1-46e7-44ce-e693-fc086fa74634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 데이터 개수: 882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 스케이링 함수 정의 및 적용\n",
        "\n",
        "def scale_data(data,new_min=0,new_max=882):\n",
        "  data = np.array(data)\n",
        "  old_min=np.min(data)\n",
        "  old_max=np.max(data)\n",
        "\n",
        "  scaled_data=(data-old_min)/(old_max-old_min) * (new_max - new_min) + new_min\n",
        "  return scaled_data.tolist()\n",
        "\n",
        "#증강된 데이터 스케일링 적용\n",
        "df_augmented[data_col]=df_augmented[data_col].apply(lambda x: scale_data(x,0,882))\n",
        "\n",
        "# 스케일링된 데이터 확인\n",
        "print(df_augmented.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk1vSjSliiJF",
        "outputId": "f7e4dee3-50f5-403a-cbe8-04cbbb81fdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             feature  label\n",
            "0  [[138.16173112392426, 283.86886274814606, 318....      9\n",
            "1  [[215.15631169080734, 373.60669934749603, 426....     10\n",
            "2  [[197.9994061589241, 260.66917580366135, 459.5...     11\n",
            "3  [[0.0, 129.4233039021492, 210.38544023036957, ...     12\n",
            "4  [[143.11933583021164, 82.42135781049728, 176.5...     13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 스케일링된 CSV 파일 경로\n",
        "output_file_path = '/content/drive/My Drive/soundAI/scaled_augmented_clean_df.csv'\n",
        "\n",
        "# 스케일링된 CSV 파일로 저장\n",
        "df_augmented.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Colab 로컬 파일 시스템에도 저장\n",
        "local_output_path = 'scaled_augmented_clean_df.csv'\n",
        "df_augmented.to_csv(local_output_path, index=False)"
      ],
      "metadata": {
        "id": "B8ZrjWB8jfYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Data(80%), Test Data(20%) 분리"
      ],
      "metadata": {
        "id": "Sx49kHskjiiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# 필드 크기 제한을 늘리기\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "# 스케일링된 CSV 파일 경로\n",
        "file_path = '/content/drive/My Drive/soundAI/scaled_augmented_clean_df.csv'\n",
        "\n",
        "# 훈련셋과 검증셋 파일 경로\n",
        "train_file_path = '/content/drive/My Drive/soundAI/train_set.csv'\n",
        "val_file_path = '/content/drive/My Drive/soundAI/val_set.csv'\n",
        "\n",
        "# 훈련셋과 검증셋의 비율\n",
        "train_ratio = 0.8\n",
        "\n",
        "# 훈련셋과 검증셋 파일 생성\n",
        "with open(file_path, 'r') as infile, \\\n",
        "     open(train_file_path, 'w', newline='') as train_file, \\\n",
        "     open(val_file_path, 'w', newline='') as val_file:\n",
        "\n",
        "    reader = csv.reader(infile)\n",
        "    train_writer = csv.writer(train_file)\n",
        "    val_writer = csv.writer(val_file)\n",
        "\n",
        "    # 헤더 읽기 및 쓰기\n",
        "    header = next(reader)\n",
        "    train_writer.writerow(header)\n",
        "    val_writer.writerow(header)\n",
        "\n",
        "    # 데이터 나누기\n",
        "    for row in reader:\n",
        "        if np.random.rand() < train_ratio:\n",
        "            train_writer.writerow(row)\n",
        "        else:\n",
        "            val_writer.writerow(row)\n",
        "\n",
        "print(\"훈련셋과 검증셋이 성공적으로 생성되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjH3HbV-jpLO",
        "outputId": "b2c56b71-15f5-454a-e847-530219e3b998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련셋과 검증셋이 성공적으로 생성되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련셋과 검증셋 CSV 파일을 로컬 파일 시스템에 저장\n",
        "local_train_file_path = 'train_set.csv'\n",
        "local_val_file_path = 'val_set.csv'\n",
        "\n",
        "# Google Drive에 저장된 파일을 로컬 파일 시스템으로 복사\n",
        "!cp \"/content/drive/My Drive/soundAI/train_set.csv\" {local_train_file_path}\n",
        "!cp \"/content/drive/My Drive/soundAI/val_set.csv\" {local_val_file_path}\n",
        "\n",
        "print(\"훈련셋과 검증셋이 로컬 파일 시스템에 저장되었습니다.\")\n",
        "\n",
        "# 파일 다운로드\n",
        "from google.colab import files\n",
        "files.download(local_train_file_path)\n",
        "files.download(local_val_file_path)\n",
        "\n",
        "print(\"훈련셋과 검증셋 파일이 다운로드되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWIMIeW2GkRZ",
        "outputId": "100abddd-fb71-458d-aa37-f83c3d5787c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련셋과 검증셋이 로컬 파일 시스템에 저장되었습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97d00299-5d80-4eee-b066-57688f09df81\", \"train_set.csv\", 1043586808)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c9904dc-a1e2-4bf1-a143-051279a9f907\", \"val_set.csv\", 276458384)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련셋과 검증셋 파일이 다운로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터를 모델에 넣기 위한 모습을 변환"
      ],
      "metadata": {
        "id": "A246SeShQYtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블 값이 모델에서 정의한 클래스 범위를 초과했음\n",
        "모델의 출력 레이어는 10개의 클래스를 예측하도록 설정되어 있지만, 데이터셋에는 그보다 많은 클래스가 있는 것 같습니다. 이 문제를 해결하기 위해 모델의 출력 레이어를 데이터셋의 실제 클래스 수에 맞춰 조정"
      ],
      "metadata": {
        "id": "afbDaQL1TE8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해결 방법\n",
        "데이터셋의 클래스 수를 확인합니다.\n",
        "모델의 출력 레이어를 이 클래스 수에 맞춰 조정합니다."
      ],
      "metadata": {
        "id": "EGB7dPjxTMaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_file_path = '/content/drive/My Drive/soundAI/train_set.csv'\n",
        "val_file_path = '/content/drive/My Drive/soundAI/val_set.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_file_path)\n",
        "val_df = pd.read_csv(val_file_path)\n",
        "\n",
        "# 레이블 값 확인\n",
        "print(f\"Training labels range: {train_df['label'].min()} - {train_df['label'].max()}\")\n",
        "print(f\"Validation labels range: {val_df['label'].min()} - {val_df['label'].max()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDaNJz0T5Fp",
        "outputId": "0ddc25ab-5632-4413-9eeb-b39f2b840b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels range: 1 - 1213\n",
            "Validation labels range: 1 - 1213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 수 확인\n",
        "num_classes = max(train_df['label'].max(), val_df['label'].max()) + 1\n",
        "print(f'Number of classes: {num_classes}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNL3rRVeUr3p",
        "outputId": "36706d5b-65cb-4f59-8341-b16160221d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import ast\n",
        "\n",
        "# 데이터 크기를 고정하는 함수 정의\n",
        "def pad_or_trim_features(features, max_length):\n",
        "    if len(features) >= max_length:\n",
        "        return features[:max_length]\n",
        "    else:\n",
        "        return np.pad(features, ((0, max_length - len(features)), (0, 0)), mode='constant', constant_values=-1)"
      ],
      "metadata": {
        "id": "ZKh1Z3egVIKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 읽고 tf.data.Dataset으로 변환하는 함수\n",
        "def csv_to_dataset(file_path, max_length=128, batch_size=32, label_col='label'):\n",
        "  def data_generator():\n",
        "    with open(file_path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            label = int(row[label_col])\n",
        "            feature = np.array(ast.literal_eval(row['feature']), dtype=np.float32)\n",
        "            feature = pad_or_trim_features(feature, max_length)\n",
        "            # 2차원 배열인 feature의 두 번째 차원이 128이 되도록 조정\n",
        "            feature = feature[:, :max_length]\n",
        "            yield feature, label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        data_generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(max_length, max_length), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "        )\n",
        "    )\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# 데이터셋 생성\n",
        "batch_size = 32\n",
        "max_length = 128\n",
        "train_dataset = csv_to_dataset('/content/drive/My Drive/soundAI/train_set.csv', max_length=max_length, batch_size=batch_size)\n",
        "val_dataset = csv_to_dataset('/content/drive/My Drive/soundAI/val_set.csv', max_length=max_length, batch_size=batch_size)\n",
        "\n",
        "# 데이터셋을 CNN 입력 형태로 변환하는 함수\n",
        "def preprocess(features, labels):\n",
        "    features = tf.expand_dims(features, -1)  # 채널 차원 추가\n",
        "    return features, labels\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess)\n",
        "val_dataset = val_dataset.map(preprocess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "lJbvX0m7VNhb",
        "outputId": "1730b620-f670-4cc9-ec24-5f9f2caaf879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-13f18c349800>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 모델 생성\n",
        "input_shape = (max_length, max_length, 1)\n",
        "num_classes = 91  # 클래스 수 설정\n",
        "model = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnS3cMmAVR_7",
        "outputId": "21056fd4-663b-42f1-ecac-5d8b48c7e13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 63, 63, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPooli  (None, 14, 14, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 91)                11739     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3315803 (12.65 MB)\n",
            "Trainable params: 3315803 (12.65 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "history = model.fit(train_dataset, epochs=3, validation_data=val_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eytwC5eHVTwf",
        "outputId": "2a9fe92d-bad5-4728-989e-f69d8bfa0cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-43-06bfee2c5e49>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 1113 which is outside the valid range of [0, 91).  Label values: 10 11 12 13 209 309 609 911 913 210 310 410 610 810 1011 1013 411 511 611 711 811 1112 1113 112 212 312 412 612 712 512 812 113\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_9311]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-06bfee2c5e49>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-43-06bfee2c5e49>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 1113 which is outside the valid range of [0, 91).  Label values: 10 11 12 13 209 309 609 911 913 210 310 410 610 810 1011 1013 411 511 611 711 811 1112 1113 112 212 312 412 612 712 512 812 113\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_9311]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시도2"
      ],
      "metadata": {
        "id": "-e4qZC-qYZl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# 데이터 로드\n",
        "df = pd.read_csv('/content/drive/My Drive/soundAI/augmented_clean_df.csv')\n"
      ],
      "metadata": {
        "id": "dOnVK_raZoaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = df.drop(columns=['label']).values\n",
        "y = df['label'].values\n",
        "\n",
        "# 훈련 세트와 테스트 세트로 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-iM9JFTnZtXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 구축\n",
        "\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "S7NNldkMZwfa",
        "outputId": "be13e760-7235-4e09-adba-7350199caf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-57baade23ddb>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시도3"
      ],
      "metadata": {
        "id": "TUAKqgjva9q0"
      }
    }
  ]
}